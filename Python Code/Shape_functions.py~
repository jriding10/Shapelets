#! /usr/bin/env python
# Shape_functions.py
# Contains a number of functions used in the shapelet main code

import io
import math as m
import numpy as np
import astropy
import pyfits

#######################################################################
## Attempts to optimise beta1, beta2: non-optimal routinue for 2 
# dependent varibles

def beta1_beta2(coords,coldata,n,ext_source):
	
	data_size = coldata.shape
	nside = m.sqrt(data_size[0])
	ang_res = abs(coords[0,1]-coords[0,0])
	nmoms = 0.5*(n+1)*(n+2)
	max_iters = 100
	fine = 10e6		# precision of the two stages
	coarse = 10e4
	resize = 32		# later speedup possibility

	# Coarse loop to isolate beta 1 and 2: Minimise beta1, then beta2.
	# If beta1 and beta2 are the same as last minimisation loop,
	# convergence is assumed.

	imsig = 100                                
	MSE = imsig                                
	prev_MSE = 2*imsig                        
	prev_beta1 = 0.9*pow(n,-0.52)*ext_source   
	prev_beta2 = 0.9*pow(n,-0.52)*ext_source    
	max_beta = 0.9*pow(n,-0.52)*nside*ang_res
	beta2 = prev_beta2                         
	step = 5*ang_res
	max_iters = 100                          
	change = 0                                 
	c1=0                                       
	c2=0                                       
	l=-1

	# coarse loop (step size of 5*ang_res) with loop limit max_iters
	while (change < 2 & l<max_iters):
		if c1 != 1:
			beta1 = prev_beta1+5*step
		while (MSE < prev_MSE):
			l=l+1 
			prev_MSE = MSE
			beta1 = beta1-step
			if beta1 < 0:
				beta1 = max_beta
			MSE = quick_model(coords,coldata,beta1,beta2,n) 
			temp[l,0] = beta1
			temp[l,1] = beta2
			temp[l,2] = MSE

	# is it a minimum? could it be a global minimum?
			if round((beta1+step)*coarse) == round(prev_beta1*coarse):
				beta1=prev_beta1
				c1=1
			else:
				prev_beta1 = beta1+step
				beta1=prev_beta1
				c2=0
				c1=0

		prev_MSE = 2*imsig;
		MSE = imsig;
    
		if c2 != 1:
			beta2= prev_beta2+5*step 
		while (MSE < prev_MSE):
			l=l+1            
			prev_MSE = MSE
			beta2 = beta2-step 
			if beta2 < 0:
				beta2 = max_beta
				MSE = quick_model(coords,coldata,beta1,beta2,n)
			temp[l,0] = beta1
			temp[l,1] = beta2
			temp[l,2] = MSE
    
	# is it a minimum? is it a global minimum?
		if round((beta2+step)*coarse) == round(prev_beta2*coarse):
			beta2=prev_beta2
			c2 = 1
		else:
			prev_beta2 = beta2+step
			beta2=prev_beta2
			c2=0
			c1=0

		change = c1+c2
    	prev_MSE = 2*imsig
    	MSE = imsig 

	# because I don't entirely trust my algorythm to find the optimal..	
	temp[np.argsort(temp[:,2])]
	prev_beta1 = temp[0,0]
	prev_beta2 = temp[0,1]
	beta2 = prev_beta2

	# Fine loop (step size=angular resolution)
	MSE = imsig                                
	prev_MSE = 2*imsig   
	step = ang_res
	force = 0 				   
	c1=0
	c2=0
	change=0

	while (change < 2 & l<2*max_iters):
		if c1 != 1:
			beta1 = prev_beta1+5*step
		while (MSE < prev_MSE):
			l=l+1 
			prev_MSE = MSE
			beta1 = beta1-step
			if beta1 < 0:
				beta1 = beta1+step
				force = 1
			MSE = quick_model(coords,coldata,beta1,beta2,n)   	    
			temp[l,0] = beta1
			temp[l,1] = beta2
			temp[l,2] = MSE

		if round((beta1+step)*fine) == round(prev_beta1*fine):
			beta1=prev_beta1
			c1=1
		elif force == 1:
			beta1=prev_beta1
			c1=1
		else:
			prev_beta1 = beta1+step
			beta1=prev_beta1
			c2=0
			c1=0

			prev_MSE = 2*imsig
			MSE = imsig
			force = 0
    	
		if c2 != 1:
			beta2= prev_beta2+5*step 
		while (MSE < prev_MSE):
			l=l+1
			prev_MSE = MSE
			beta2 = beta2-step 
			if beta2 < 0:
				beta2 = beta2+step
				force = 1
			MSE = quick_model(coords,coldata,beta1,beta2,n)          
			temp[l,0]=beta1
			temp[l,1]=beta2
			temp[l,2]=MSE           
    
		if round((beta2+step)*fine) == round(prev_beta2*fine):
			beta2=prev_beta2
			c2 = 1
		elif force == 1:
			beta2=prev_beta2
			c2=1
		else:
			prev_beta2 = beta2+step
			beta2=prev_beta2
			c2=0
			c1=0

		change = c1+c2
		prev_MSE = 2*imsig
		MSE = imsig    

	l=l+1
	temp[l,0]=beta1
	temp[l,1]=beta2
	temp[l,2]=MSE   
	
	temp[np.argsort(temp[:,2])]
	beta1 = temp[0,0]
	beta2 = temp[0,1]

	return (beta1, beta2)

#######################################################################
## Determines the shapelet moments

def deconstruct(coords, coldata, beta1, beta2, nmax):

	min_percent = 0.0	# zero small coefficients
	tot_moms = 0.5*(nmax+1)*(nmax+2)
	f_coeffs = np.zeros((tot_moms,3))
	data_size = coldata.shape
	npix = data_size[0]
	Mpiece = np.zeros((npix,1))
	M = basis(coords, beta1, beta2, nmax)
	check = 0.

	i=-1
	for n1 in range(0,nmax):
		for n2 in range(0,nmax):
			if (n1+n2)<=nmax:			
				Mpiece[:,0] = M[:,n1,n2]
				demon = np.dot(np.transpose(Mpiece),Mpiece)
				numer = np.dot(np.transpose(Mpiece),coldata)
				fhat = numer/demon
				if (n1+n2) == 0:
					fmax = fhat
				if abs(fhat) > min_percent*fmax:
					i=i+1
					f_coeffs[i,0]=n1
					f_coeffs[i,1]=n2
					f_coeffs[i,2]=fhat
				else:
					i=i+1
					f_coeffs[i,0]=n1
					f_coeffs[i,1]=n2
					f_coeffs[i,2]=0.0	
	
	return f_coeffs

#######################################################################
## Creates the orthogonal basis functions

def basis(coords,beta1,beta2,nmax):

	hermites = np.loadtxt('hermite_coeffs.txt')
	xrot = beta1*coords[:,0]
	yrot = beta2*coords[:,1]
	data_size = coords.shape
	npix = data_size[0]
	all_basis = np.zeros((npix,nmax+1,nmax+1))	

	gauss = np.exp(-0.5*(np.array(xrot)**2+np.array(yrot)**2))	
	n1 = 0                                  
	n2 = 0
	for n1 in range(0,nmax):
		n2 = 0
		while (n1+n2) <= nmax:
			norm = m.sqrt(m.pow(2,n1+n2)*m.pi*beta1*beta2*m.factorial(n1)*m.factorial(n2))
			k=0
			h1=0.
			h2=0.
			while (k <= n1):		
				h1 = h1+hermites[n1, k]*(np.array(xrot))**(n1-k)
				k=k+1
			k=0
			while (k <= n2):
				h2 = h2+hermites[n2, k]*(np.array(yrot))**(n2-k)
				k=k+1
			M = gauss/norm*h1*h2
			all_basis[:, n1, n2] = M
			n2 = n2+1

	return all_basis

#######################################################################
## Calculates some simple statistics about the data - NMSE & PSNR

def simple_stats(coldata, colmod):

	data_size = coldata.shape
	npix = data_size[0]
	performance = np.zeros((2))
	norm = 0
	mse = 0
	PSNR = 0

	for i in range(0,npix-1):
   	    z = coldata[i] - colmod[i]
   	    mse = mse + z*z

	NMSE = mse/npix

	G = np.max(coldata)

	PSNR = 20*np.log10(G)-10*np.log10(NMSE)
	performance[0] = NMSE
	performance[1] = PSNR

	return performance

#######################################################################
## Handles the function calls of beta1_beta2

def quick_model(coords,coldata,beta1,beta2,n):

	data_size = coords.shape
	npix = data_size[0]
	tot_moms = 0.5*(n-1)*(n-2)		
	temp_moments = np.zeros((tot_moms,3))
 	temp_mod = np.zeros((npix,1))

	temp_moments = deconstruct(coords,coldata,beta1,beta2,n)
	temp_mod = reconstruct(coords,temp_moments,beta1,beta2)
	performance = simple_stats(coldata,temp_mod)

	return performance[0]

#######################################################################
## reconstructs the model

def reconstruct(coords,moments,beta1,beta2):

	data_size = coords.shape
	npix = data_size[0]
	mom_size = moments.shape
	tot_coeffs = mom_size[0]
	n = int(max(moments[:,0]))
	Mpiece = np.zeros((npix,1))
	colmod = np.zeros((npix,1))

	M = basis(coords,beta1,beta2,n)
	
	for i in range(0,tot_coeffs):
		n1 = int(moments[i,0])
		n2 = int(moments[i,1])
		f_hat = moments[i,2]
		Mpiece[:,0] = M[:,n1,n2]
		colmod += f_hat*(Mpiece)
	
	return colmod

#######################################################################
